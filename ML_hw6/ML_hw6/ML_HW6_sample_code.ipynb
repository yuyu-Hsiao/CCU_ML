{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KSCsJ0y2XTY"
      },
      "source": [
        "# ML Assignment 6 - Sample Code\n",
        "* 雲端硬碟: https://drive.google.com/drive/folders/1KqXE_drqYYwg9RsQil3oXQeskXzuATdR?usp=sharing\n",
        "* 蘭花競賽網站: https://tbrain.trendmicro.com.tw/Competitions/Details/20\n",
        "\n",
        "## 執行方式\n",
        "資料集請去雲端硬碟取得(./dataset)，內有壓縮檔可下載\n",
        "\n",
        "依作業要求，在圖像轉換區塊更改程式碼。\n",
        "訓練過程及輸出位於最後面。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOJJwMUtveYP"
      },
      "source": [
        "## 初始設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "JFMiIumfJBeA",
        "outputId": "77b437f4-39cb-49d1-b7c5-256863c8be77"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut6ZO3ltIB9N",
        "outputId": "a64e8e84-4ec7-4a3b-f485-de67205f7670"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMZdfef0rZw0"
      },
      "source": [
        "將剛才取得的資料集整個複製到你自己雲端上，並更改下面路徑到你自己的資料集目錄\n",
        "\n",
        "(\"/content/drive/MyDrive/\" 是雲端固定的位址，請自行建立資料夾，並將資料集放置在內 ex:\"ML_CNN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFmIGG36rZOY",
        "outputId": "9e5a0bd7-51c9-4c35-9922-ff622edc7ba8"
      },
      "outputs": [],
      "source": [
        "#%cd /content/drive/MyDrive/ML_CNN\n",
        "#%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uncYZYULmuqp",
        "outputId": "2ffb80e4-52c6-464b-bb5b-bf46ef8c372a"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.hub import load_state_dict_from_url\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsUYQ1BPvH7a"
      },
      "source": [
        "## 圖像轉換\n",
        "### 題目\n",
        "torchvision.transforms 提供了許多可靠的 API來讓使用者對圖像進行操作，請試著在 data transforms 當中對訓練集進行轉換(圖像前處理)，當模型訓練到一定程度時，驗證看看使用該方法是否確實對模型準確率造成影響\n",
        "\n",
        "* **Weak Augmentation** - 使用**1**種data transforms，並記錄其**使用前、使用後的validation accuracy**，共做1~3次\n",
        "\n",
        "* **Strong Augmentation** - 使用**4~6**種data transforms，並記錄其**使用前、使用後的validation accuracy**\n",
        "\n",
        "### 下面列出目前全部可用的transforms，參數部分自行Google :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srb7qsQ-Aa4q",
        "outputId": "511d70cf-9ecc-4d81-a4e4-5c7e708cb8b6"
      },
      "outputs": [],
      "source": [
        "transforms_list = dir(transforms)\n",
        "available_transforms = [name for name in transforms_list if not name.startswith(\"__\")]\n",
        "num=0\n",
        "# 輸出可用的transforms函數\n",
        "for transform in available_transforms:\n",
        "    num+=1\n",
        "    print(num,\".\",transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGtGuG6rni4T"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize((224,224) ),\n",
        "            ########在此區塊填入圖像轉換方法########\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0, saturation=0, hue=0),\n",
        "            transforms.RandomRotation(degrees=5),\n",
        "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
        "            ########################################\n",
        "            transforms.ToTensor(),\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize((224,224) ),\n",
        "            transforms.ToTensor(),\n",
        "        ]),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize((224,224) ),\n",
        "            ########在此區塊填入圖像轉換方法########\n",
        "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
        "            ########################################\n",
        "            transforms.ToTensor(),\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize((224,224) ),\n",
        "            transforms.ToTensor(),\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0, saturation=0, hue=0),\n",
        "            transforms.RandomRotation(degrees=5),\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORjQXKTVmyuA"
      },
      "outputs": [],
      "source": [
        "class MyCNN(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes=1000):\n",
        "    super(MyCNN, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "      nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "      nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "      nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    )\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(256 * 6 * 6, 4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(4096, 4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "    )\n",
        "    self.classifier2 = nn.Sequential(\n",
        "      nn.Linear(4096, num_classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.classifier(x)\n",
        "    x = self.classifier2(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNezyEHCGbiq"
      },
      "source": [
        "## 訓練模型區塊\n",
        "包含視覺化模型及訓練模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkP2g__jm8M4"
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, device, dataloaders, class_names, num_images=6):\n",
        "  was_training = model.training\n",
        "  model.eval()\n",
        "  images_so_far = 0\n",
        "\n",
        "  plt.figure(figsize=(18,9))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "\n",
        "      for j in range(inputs.size()[0]):\n",
        "        images_so_far += 1\n",
        "\n",
        "        img_display = np.transpose(inputs.cpu().data[j].numpy(), (1,2,0)) #numpy:CHW, PIL:HWC\n",
        "        plt.subplot(num_images//2,2,images_so_far),plt.imshow(img_display) #nrow,ncol,image_idx\n",
        "        plt.title(f'predicted: {class_names[preds[j]]}')\n",
        "        plt.savefig(\"test.jpg\")\n",
        "        if images_so_far == num_images:\n",
        "            model.train(mode=was_training)\n",
        "            plt.clf()\n",
        "            return\n",
        "    plt.clf()\n",
        "    model.train(mode=was_training)\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "  \"\"\"Imshow for Tensor.\"\"\"\n",
        "  inp = inp.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "  #原先Normalize是對每個channel個別做 減去mean, 再除上std\n",
        "  inp1 = std * inp + mean\n",
        "\n",
        "  plt.imshow(inp)\n",
        "\n",
        "  if title is not None:\n",
        "      plt.title(title)\n",
        "  plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "  plt.imshow(inp1)\n",
        "  if title is not None:\n",
        "      plt.title(title)\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-dRfFb3q6Vm"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, device, dataloaders, dataset_sizes, optimizer, scheduler, num_epochs=25):\n",
        "  since = time.time()\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "  train_loss, valid_loss = [], []\n",
        "  train_acc, valid_acc = [], []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train()  # Set model to training mode\n",
        "      else:\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      # Iterate over data.\n",
        "      for inputs, labels in tqdm(dataloaders[phase]):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # backward + optimize only if in training phase\n",
        "            if phase == 'train':\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "      if phase == 'train':\n",
        "        scheduler.step()\n",
        "\n",
        "      epoch_loss = running_loss / dataset_sizes[phase]\n",
        "      epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "      if phase == 'train':\n",
        "        train_loss.append(epoch_loss)\n",
        "        train_acc.append(epoch_acc)\n",
        "      else:\n",
        "        valid_loss.append(epoch_loss)\n",
        "        valid_acc.append(epoch_acc)\n",
        "\n",
        "      print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        phase, epoch_loss, epoch_acc))\n",
        "\n",
        "      # deep copy the model\n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "  plt.figure(0)\n",
        "  plt.plot(range(1,num_epochs+1,1), np.array(train_loss), 'r-', label= \"train loss\") #relative global step\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(f\"./train_loss.png\")\n",
        "  plt.clf()\n",
        "\n",
        "  plt.figure(1)\n",
        "  plt.plot(range(1,num_epochs+1,1), np.array(valid_loss), 'b-', label= \"eval loss\") #--evaluate_during_training True 在啟用eval\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(f\"./eval_loss.png\")\n",
        "  plt.clf()\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "    time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "  # load best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  #torch.save(model.state_dict(),\"model.pt\")\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftlKnYzrqzeL"
      },
      "source": [
        "## 訓練參數\n",
        "* num_epochs: 訓練回合數\n",
        "* lr: 訓練速度(learning rate)\n",
        "* batch_size: 批次(batch)大小"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jje5_QtQqu7A"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20\n",
        "lr = 0.001\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4To2Db6HG8vI"
      },
      "source": [
        "## 主函式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XbiXj6gt2nFY",
        "outputId": "0cd5bd75-1733-446e-fad5-507a8a3cd5de"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  num_workers = 2\n",
        "  momentum = 0.9\n",
        "\n",
        "  # 資料集載入 =======================================================================\n",
        "  data_dir = 'ML_CNN/dataset/training'\n",
        "  image_datasets = {\n",
        "    x: datasets.ImageFolder(\n",
        "      os.path.join(data_dir, x),\n",
        "      data_transforms[x]\n",
        "    )\n",
        "    for x in ['train', 'val']     \n",
        "  }\n",
        "  dataloaders = {\n",
        "    x: torch.utils.data.DataLoader(\n",
        "      image_datasets[x],\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers\n",
        "    )\n",
        "    for x in ['train', 'val']\n",
        "  }\n",
        "  dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "  class_names = image_datasets['train'].classes\n",
        "  # 資料集載入 =======================================================================\n",
        "\n",
        "  # 設定 CUDA 環境 =======================================================================\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Using device {device}\\n\")\n",
        "  # 設定 CUDA 環境 =======================================================================\n",
        "\n",
        "\n",
        "  # Get a batch of training data\n",
        "  inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "  # Make a grid from batch\n",
        "  out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "  imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "\n",
        "  # model =======================================================================\n",
        "  model_ft = MyCNN(num_classes=219)\n",
        "  pretrained_dict = load_state_dict_from_url(\n",
        "    'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "    progress=True\n",
        "  )\n",
        "  model_dict = model_ft.state_dict()\n",
        "  # 1. filter out unnecessary keys\n",
        "  pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "  # 2. overwrite entries in the existing state dict\n",
        "  model_dict.update(pretrained_dict)\n",
        "  # 3. load the new state dict\n",
        "  model_ft.load_state_dict(model_dict)\n",
        "\n",
        "  for k,v in model_dict.items():\n",
        "    print(k)\n",
        "\n",
        "  model_ft = model_ft.to(device)\n",
        "  # model =======================================================================\n",
        "\n",
        "  parameter_count = count_parameters(model_ft)\n",
        "  print(f\"#parameters:{parameter_count}\")\n",
        "  print(f\"batch_size:{batch_size}\")\n",
        "\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Observe that all parameters are being optimized\n",
        "  optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "  # Decay LR by a factor of 0.1 every 7 epochs\n",
        "  exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "  model_ft = train_model(\n",
        "    model_ft,\n",
        "    criterion,\n",
        "    device,\n",
        "    dataloaders,\n",
        "    dataset_sizes,\n",
        "    optimizer_ft,\n",
        "    exp_lr_scheduler,\n",
        "    num_epochs=num_epochs\n",
        "  )\n",
        "  class_names = image_datasets['val'].classes\n",
        "  visualize_model(model_ft, device, dataloaders, class_names)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
